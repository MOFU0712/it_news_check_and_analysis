{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OdFEEMV2CVOaZA2bjYrdR6Ry_ZRsOM4x",
      "authorship_tag": "ABX9TyOMFXR7B0iibPnVSY0j/1aO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MOFU0712/it_news_check_and_analysis/blob/main/news_check_in_notion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic\n",
        "!pip install notion_client"
      ],
      "metadata": {
        "id": "ZRdnvZAnHy0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3cc218-ba31-46c3-d45f-bbe31df8b0ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.49.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Requirement already satisfied: notion_client in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from notion_client) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->notion_client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->notion_client) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->notion_client) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->notion_client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->notion_client) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->notion_client) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->notion_client) (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ニュースページの要約"
      ],
      "metadata": {
        "id": "HeCVwwMU2P7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from notion_client import Client\n",
        "from anthropic import Anthropic\n",
        "\n",
        "# NotionとAnthropicのAPI設定\n",
        "NOTION_TOKEN = userdata.get('NOTION_API_KEY')\n",
        "NOTION_DATABASE_ID = userdata.get('PICKUP_DATABASE_KEY')\n",
        "ANTHROPIC_API_KEY = userdata.get('CLAUDE_API_KEY')\n",
        "\n",
        "# NotionとAnthropicのクライアント初期化\n",
        "notion = Client(auth=NOTION_TOKEN)\n",
        "anthropic = Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "def get_page_content(page_id):\n",
        "    \"\"\"ページの本文コンテンツを取得する\"\"\"\n",
        "    blocks = notion.blocks.children.list(block_id=page_id)\n",
        "    content = \"\"\n",
        "\n",
        "    for block in blocks[\"results\"]:\n",
        "        if block[\"type\"] == \"paragraph\":\n",
        "            try:\n",
        "                content += block[\"paragraph\"][\"rich_text\"][0][\"text\"][\"content\"] + \"\\n\"\n",
        "            except (KeyError, IndexError):\n",
        "                continue\n",
        "\n",
        "    return content\n",
        "\n",
        "def extract_text_from_response(response):\n",
        "    \"\"\"APIレスポンスからテキスト部分のみを抽出する\"\"\"\n",
        "    if hasattr(response, 'text'):\n",
        "        return response.text\n",
        "    elif isinstance(response, list) and len(response) > 0:\n",
        "        first_block = response[0]\n",
        "        if hasattr(first_block, 'text'):\n",
        "            return first_block.text\n",
        "    return str(response)\n",
        "\n",
        "def generate_summary(content):\n",
        "    \"\"\"Claude 3.5 Haikuを使用して要約を生成する\"\"\"\n",
        "    if not content.strip():\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        message = anthropic.messages.create(\n",
        "            model=\"claude-3-haiku-20240307\",\n",
        "            # model='claude-3-7-sonnet-20250219',\n",
        "            max_tokens=300,\n",
        "            messages=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"以下の文章をニュースまとめ記事用に、**必ず日本語**で、2文程度で簡潔に要約してください。箇条書きではなく、文章として書き、文体はですます調で、出力は要約文だけでお願いします。：\\n\\n{content}\"\n",
        "            }]\n",
        "        )\n",
        "\n",
        "        # メッセージの内容からテキスト部分のみを抽出\n",
        "        content = message.content\n",
        "        summary = extract_text_from_response(content)\n",
        "\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating summary: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def update_empty_summaries():\n",
        "    \"\"\"summaryが空のページを検索し、要約を生成して更新する\"\"\"\n",
        "    try:\n",
        "        # データベースの全ページを取得\n",
        "        pages = notion.databases.query(\n",
        "            database_id=NOTION_DATABASE_ID,\n",
        "            filter={\n",
        "                \"property\": \"summary\",\n",
        "                \"rich_text\": {\n",
        "                    \"is_empty\": True\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "\n",
        "        for page in pages[\"results\"]:\n",
        "            try:\n",
        "                page_id = page[\"id\"]\n",
        "\n",
        "                # ページの本文を取得\n",
        "                content = get_page_content(page_id)\n",
        "\n",
        "                # 要約を生成\n",
        "                summary = generate_summary(content)\n",
        "\n",
        "                if summary:\n",
        "                    # summaryプロパティを更新\n",
        "                    notion.pages.update(\n",
        "                        page_id=page_id,\n",
        "                        properties={\n",
        "                            \"summary\": {\n",
        "                                \"rich_text\": [{\n",
        "                                    \"type\": \"text\",\n",
        "                                    \"text\": {\n",
        "                                        \"content\": summary\n",
        "                                    }\n",
        "                                }]\n",
        "                            }\n",
        "                        }\n",
        "                    )\n",
        "                    print(f\"Updated summary for page {page_id}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing page {page_id}: {e}\")\n",
        "                continue\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying database: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    update_empty_summaries()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BZoj40g06Ag",
        "outputId": "bd8c5985-935f-461f-cdad-17bb20627d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated summary for page 1d96a7ec-2649-8159-9bc5-e0ac365790b4\n",
            "Updated summary for page 1d96a7ec-2649-8104-8143-e5021b900964\n",
            "Updated summary for page 1d96a7ec-2649-81eb-a656-cfb7a458f4e1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MBJe58PHB4bK"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from datetime import datetime, timedelta, date\n",
        "from google.colab import userdata\n",
        "import anthropic\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "def pick_daily_news_from_database(url, headers):\n",
        "\n",
        "\n",
        "# データベースからデータを取得するためのフィルター\n",
        "    data = {\n",
        "        \"filter\": {\n",
        "            \"and\": [\n",
        "                {\n",
        "                    \"property\": \"flag\",\n",
        "                    \"status\": {\n",
        "                        \"equals\": \"pick\"\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"or\": [\n",
        "                        {\n",
        "                            \"property\": \"pickup_type\",\n",
        "                            \"select\": {\n",
        "                                \"equals\": \"day\"\n",
        "                            }\n",
        "                        },\n",
        "                        {\n",
        "                            \"property\": \"pickup_type\",\n",
        "                            \"select\": {\n",
        "                                \"equals\": \"week\"\n",
        "                            }\n",
        "                        },\n",
        "                        {\n",
        "                            \"property\": \"pickup_type\",\n",
        "                            \"select\": {\n",
        "                                \"equals\": \"month\"\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # APIリクエストを送信\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    results = response.json()\n",
        "    return results\n",
        "\n",
        "def pick_weekly_news_from_database(url, headers):\n",
        "\n",
        "\n",
        "# データベースからデータを取得するためのフィルター\n",
        "    data = {\n",
        "        \"filter\": {\n",
        "            \"and\": [\n",
        "                {\n",
        "                    \"property\": \"flag\",\n",
        "                    \"status\": {\n",
        "                        \"equals\": \"pick\"\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"or\": [\n",
        "                        {\n",
        "                            \"property\": \"pickup_type\",\n",
        "                            \"select\": {\n",
        "                                \"equals\": \"week\"\n",
        "                            }\n",
        "                        },\n",
        "                        {\n",
        "                            \"property\": \"pickup_type\",\n",
        "                            \"select\": {\n",
        "                                \"equals\": \"month\"\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # APIリクエストを送信\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    results = response.json()\n",
        "    return results\n",
        "\n",
        "def pick_monthly_news_from_database(url, headers):\n",
        "\n",
        "\n",
        "    # データベースからデータを取得するためのフィルター\n",
        "    data = {\n",
        "        \"filter\": {\n",
        "            \"and\": [\n",
        "                {\n",
        "                    \"property\": \"flag\",\n",
        "                    \"status\": {\n",
        "                        \"equals\": \"pick\"\n",
        "                    }\n",
        "                },\n",
        "                {\n",
        "                    \"property\": \"pickup_type\",\n",
        "                    \"select\": {\n",
        "                        \"equals\": \"month\"\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "    # APIリクエストを送信\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    results = response.json()\n",
        "    return results\n",
        "\n",
        "def add_page_to_database(page_title, database_key, news_contents):\n",
        "\n",
        "    NOTION_API_KEY = userdata.get('NOTION_API_KEY')\n",
        "    DATABASE_ID = userdata.get(database_key)\n",
        "\n",
        "    url = 'https://api.notion.com/v1/pages'\n",
        "\n",
        "    headers =  {\n",
        "        'Notion-Version': '2022-06-28',\n",
        "        'Authorization': 'Bearer ' + NOTION_API_KEY,\n",
        "        'Content-Type': 'application/json',\n",
        "    }\n",
        "\n",
        "    json_data = {\n",
        "        'parent': { 'database_id': DATABASE_ID },\n",
        "        'properties': {\n",
        "            'name': {\n",
        "                'title': [\n",
        "                    {\n",
        "                        'text': {\n",
        "                            'content': page_title\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "\n",
        "    page_response = requests.post('https://api.notion.com/v1/pages', headers=headers, json=json_data)\n",
        "    new_page_id = page_response.json()['id']  # 新しく作成されたページのIDを取得\n",
        "    return new_page_id\n",
        "\n",
        "def add_content_to_page(headers, new_page_id, text):\n",
        "\n",
        "\n",
        "    # ページにブロック（テキスト）を追加\n",
        "    block_data = {\n",
        "        \"children\": [\n",
        "            {\n",
        "                \"object\": \"block\",\n",
        "                \"type\": \"paragraph\",\n",
        "                \"paragraph\": {\n",
        "                    \"rich_text\": [\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": {\n",
        "                                \"content\": text\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    block_response = requests.patch(f'https://api.notion.com/v1/blocks/{new_page_id}/children', headers=headers, json=block_data)\n",
        "\n",
        "def split_text(long_text, length=2000):\n",
        "    return [long_text[i:i+length] for i in range(0, len(long_text), length)]\n",
        "\n",
        "def main(pickup_type, title_date, title_name):\n",
        "    NOTION_API_KEY = userdata.get('NOTION_API_KEY')\n",
        "    DATABASE_ID = userdata.get('PICKUP_DATABASE_KEY')\n",
        "\n",
        "    url = f'https://api.notion.com/v1/databases/{DATABASE_ID}/query'\n",
        "\n",
        "    headers =  {\n",
        "        'Notion-Version': '2022-06-28',\n",
        "        'Authorization': 'Bearer ' + NOTION_API_KEY,\n",
        "        'Content-Type': 'application/json',\n",
        "    }\n",
        "\n",
        "    today = date.today()\n",
        "    formatted_date = today.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    if pickup_type == \"day\":\n",
        "        update_database_key = \"DAILY_DATABASE_KEY\"\n",
        "        results = pick_daily_news_from_database(url, headers)\n",
        "        page_title_header = \"daily_news\"\n",
        "    elif pickup_type == \"week\":\n",
        "        update_database_key = \"WEEKLY_DATABASE_KEY\"\n",
        "        results = pick_weekly_news_from_database(url, headers)\n",
        "        page_title_header = \"weekly_news\"\n",
        "    elif pickup_type == \"month\":\n",
        "        update_database_key = \"MONTHLY_DATABASE_KEY\"\n",
        "        results = pick_monthly_news_from_database(url, headers)\n",
        "        page_title_header = \"monthly_news\"\n",
        "\n",
        "    contents_list = []\n",
        "    for result in results[\"results\"]:\n",
        "        properties = result[\"properties\"]\n",
        "        news_url = properties[\"URL\"][\"url\"]\n",
        "        tag = properties[\"tag\"][\"select\"][\"name\"]\n",
        "        if not properties[\"summary\"][\"rich_text\"]:\n",
        "            print(\"summaryが空です\")\n",
        "            abstract = \"\"\n",
        "        else:\n",
        "            abstract = properties[\"summary\"][\"rich_text\"][0][\"text\"][\"content\"]\n",
        "        title = properties[\"name\"][\"title\"][0][\"text\"][\"content\"]\n",
        "        content = [tag, title, news_url, abstract]\n",
        "        contents_list.append(content)\n",
        "\n",
        "    sorted_contents_list = sorted(contents_list, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    news_contents = \"\"\n",
        "    for content in sorted_contents_list:\n",
        "        tag = content[0]\n",
        "        title = content[1]\n",
        "        news_url = content[2]\n",
        "        abstract = content[3]\n",
        "\n",
        "        news_contents += f\"\\n【{tag}】 {title} {news_url} \\n {abstract} \\n --------------------------------\"\n",
        "\n",
        "\n",
        "    page_title = f\"{page_title_header}{title_date}{title_name}\"\n",
        "\n",
        "\n",
        "    new_page_id = add_page_to_database(page_title, update_database_key, news_contents)\n",
        "\n",
        "    contents = split_text(news_contents)\n",
        "\n",
        "    for content in contents:\n",
        "        add_content_to_page(headers, new_page_id, content)\n",
        "\n",
        "    return news_contents\n",
        "\n",
        "def split_news_articles(text: str) -> List[str]:\n",
        "  \"\"\"\n",
        "  入力テキストを個別のニュース記事に分割する\n",
        "\n",
        "  Args:\n",
        "      text (str): 入力テキスト\n",
        "\n",
        "  Returns:\n",
        "      List[str]: 個別のニュース記事のリスト\n",
        "  \"\"\"\n",
        "  articles = text.split('-----------------------------')\n",
        "  return [article.strip() for article in articles if article.strip()]\n",
        "\n",
        "def process_individual_news(client: anthropic.Client, article: str) -> str:\n",
        "    \"\"\"\n",
        "    個別のニュース記事を処理する\n",
        "\n",
        "    Args:\n",
        "        client: Anthropic APIクライアント\n",
        "        article (str): 1つのニュース記事\n",
        "\n",
        "    Returns:\n",
        "        str: 処理済みの記事（タイトルと要約）\n",
        "    \"\"\"\n",
        "    system_prompt = \"\"\"\n",
        "    以下のニュース記事を処理してください：\n",
        "    1. 20語程度の一文でタイトルを作成\n",
        "    2. 200文字程度、2-3文で要約\n",
        "    3. 以下の形式で出力：\n",
        "\n",
        "    [OUTPUT_START]\n",
        "    作成したニュースタイトル\n",
        "    【タグ】ニュースの要約文 ニュースのURL\n",
        "    [OUTPUT_END]\n",
        "\n",
        "    ・元テキストの【】タグをそのまま使用\n",
        "    ・ですます調で記述\n",
        "    \"\"\"\n",
        "\n",
        "    message = client.messages.create(\n",
        "        model=\"claude-3-5-sonnet-20241022\",\n",
        "        max_tokens=1000,\n",
        "        temperature=0,\n",
        "        system=system_prompt,\n",
        "        messages=[{\"role\": \"user\", \"content\": article}]\n",
        "    )\n",
        "\n",
        "    response = message.content[0].text\n",
        "\n",
        "    # 出力を抽出\n",
        "    start_idx = response.find('[OUTPUT_START]') + len('[OUTPUT_START]')\n",
        "    end_idx = response.find('[OUTPUT_END]')\n",
        "    return response[start_idx:end_idx].strip()\n",
        "\n",
        "def generate_title_and_impression(client: anthropic.Client, summaries: str) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    全ての要約からタイトルと感想を生成\n",
        "\n",
        "    Args:\n",
        "        client: Anthropic APIクライアント\n",
        "        summaries (str): 全ての記事の要約\n",
        "\n",
        "    Returns:\n",
        "        Tuple[str, str]: (総合タイトル, 感想)\n",
        "    \"\"\"\n",
        "    system_prompt = \"\"\"\n",
        "    以下のニュース要約から、総合タイトルと感想を生成してください。\n",
        "\n",
        "    タイトル:\n",
        "    ・形式：「[主要ニュースのポイントをカンマ区切りで6つ程度]｜[月日]のIT・AIニュースピックアップ！」\n",
        "    ・重要ニュース、インパクトの大きな出来事、新しい潮流を優先\n",
        "    ・モデル名や製品、サービス名はかぎかっこ書きで必ず入れて下さい\n",
        "    ・OpenAI, Google, Anthropic, Microsoft, Amazon, ByteDance,Alibaba,Sakana AIのニュースは必ず入れてください\n",
        "\n",
        "\n",
        "    感想:\n",
        "    ・タイトルで選んだキーワードを盛り込む\n",
        "    ・タイトルに選んだニュースの詳細を記述（要約文を加工）\n",
        "    ・ニュースの詳細のあとに、未来の展望・将来予想のような感想を記述\n",
        "    ・ニュースはひとつひとつ感想を記載（まとめない）\n",
        "    ・親しみやすく優しいが丁寧な人柄が感じられる文体\n",
        "    ・1000文字程度\n",
        "\n",
        "    必ず以下の形式で出力してください：\n",
        "    [TITLE_START]\n",
        "    （総合タイトル）\n",
        "    [TITLE_END]\n",
        "\n",
        "    [IMPRESSION_START]\n",
        "    （ニュースの感想）\n",
        "    [IMPRESSION_END]\n",
        "    \"\"\"\n",
        "\n",
        "    message = client.messages.create(\n",
        "        model=\"claude-3-7-sonnet-20250219\",\n",
        "        max_tokens=2000,\n",
        "        temperature=0,\n",
        "        system=system_prompt,\n",
        "        messages=[{\"role\": \"user\", \"content\": summaries}]\n",
        "    )\n",
        "\n",
        "    response = message.content[0].text\n",
        "\n",
        "    # タイトルと感想を抽出\n",
        "    title = response[response.find('[TITLE_START]')+len('[TITLE_START]'):response.find('[TITLE_END]')].strip()\n",
        "    impression = response[response.find('[IMPRESSION_START]')+len('[IMPRESSION_START]'):response.find('[IMPRESSION_END]')].strip()\n",
        "\n",
        "    return title, impression\n",
        "\n",
        "def process_all_news(input_text: str) -> Tuple[str, str, str]:\n",
        "    \"\"\"\n",
        "    全てのニュースを処理する\n",
        "\n",
        "    Args:\n",
        "        input_text (str): 入力テキスト\n",
        "\n",
        "    Returns:\n",
        "        Tuple[str, str, str]: (ニュースまとめ, 総合タイトル, 感想)\n",
        "    \"\"\"\n",
        "    api_key = userdata.get('CLAUDE_API_KEY')\n",
        "    client = anthropic.Client(api_key=api_key)\n",
        "\n",
        "    # ニュースを分割\n",
        "    articles = split_news_articles(input_text)\n",
        "\n",
        "    # 各ニュースを個別に処理\n",
        "    processed_articles = []\n",
        "    for article in articles:\n",
        "        try:\n",
        "            processed = process_individual_news(client, article)\n",
        "            processed_articles.append(processed)\n",
        "        except Exception as e:\n",
        "            print(f\"記事の処理中にエラーが発生: {str(e)}\")\n",
        "\n",
        "    # 全ての処理済み記事を結合\n",
        "    all_summaries = \"\\n\\n\".join(processed_articles)\n",
        "\n",
        "    # タイトルと感想を生成\n",
        "    title, impression = generate_title_and_impression(client, all_summaries)\n",
        "\n",
        "    return all_summaries, title, impression\n",
        "\n",
        "def format_news_articles_for_note(text):\n",
        "    \"\"\"\n",
        "    ニュース記事のテキストをnoteのエディタ向けに整形する関数\n",
        "    様々なタグに対応し、完全に独立したブロックを作成します\n",
        "\n",
        "    Args:\n",
        "        text (str): 複数のニュース記事を含む入力テキスト\n",
        "\n",
        "    Returns:\n",
        "        str: note用に整形されたニュース記事テキスト\n",
        "    \"\"\"\n",
        "    # システムの改行コードを使用\n",
        "    newline = os.linesep\n",
        "\n",
        "    # URLで記事を分割するパターン\n",
        "    # URLの後に改行または文字列終端があるものを検出\n",
        "    pattern = r'(.*?https://[^\\s]+)(?:\\n|$)'\n",
        "\n",
        "    # 記事を抽出\n",
        "    articles = re.findall(pattern, text, re.DOTALL)\n",
        "\n",
        "    formatted_articles = []\n",
        "    for article in articles:\n",
        "        # URLを抽出\n",
        "        url_pattern = r'(https://[^\\s]+)$'\n",
        "        url_match = re.search(url_pattern, article)\n",
        "        if not url_match:\n",
        "            continue\n",
        "\n",
        "        url = url_match.group(1)\n",
        "\n",
        "        # URLを除いた部分を取得\n",
        "        content = article[:url_match.start()].strip()\n",
        "\n",
        "        # タグパターンを検出（【...】の形式）\n",
        "        tag_pattern = r'【[^】]+】'\n",
        "\n",
        "        # 最初のタグの位置を検索\n",
        "        tag_matches = list(re.finditer(tag_pattern, content))\n",
        "        if not tag_matches:\n",
        "            continue\n",
        "\n",
        "        # タイトルは最初のタグの前まで\n",
        "        first_tag_pos = tag_matches[0].start()\n",
        "        title = content[:first_tag_pos].strip()\n",
        "\n",
        "        # タグと説明文を抽出\n",
        "        tag_content = content[first_tag_pos:].strip()\n",
        "\n",
        "        # 段落区切りを使用して整形\n",
        "        formatted_parts = [\n",
        "            f\"### {title}\",\n",
        "            tag_content,\n",
        "            url\n",
        "        ]\n",
        "\n",
        "        # 各パートを段落区切りで結合\n",
        "        formatted_article = f\"{newline}{newline}\".join(formatted_parts)\n",
        "        formatted_articles.append(formatted_article)\n",
        "\n",
        "    # 記事間により大きな区切りを入れる\n",
        "    article_separator = f\"{newline}{newline}{newline}\"\n",
        "    return article_separator.join(formatted_articles)\n",
        "\n",
        "def display_news_markdown(news_title, news_impression, formatted_result):\n",
        "    \"\"\"\n",
        "    ニュース関連の出力をマークダウン形式で表示する\n",
        "\n",
        "    Args:\n",
        "        news_title (str): ニュースのタイトル\n",
        "        news_impression (str): ニュースの感想\n",
        "        formatted_result (str): フォーマット済みのニュース本文\n",
        "    \"\"\"\n",
        "    markdown_content = f\"\"\"# {news_title}\n",
        "\n",
        "こんにちは、MOFUです。\n",
        "\n",
        "{news_impression}\n",
        "\n",
        "{formatted_result}\n",
        "\"\"\"\n",
        "    display(Markdown(markdown_content))\n",
        "\n",
        "from typing import List, Dict\n",
        "from collections import defaultdict\n",
        "\n",
        "def extract_news_from_results(results: dict) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Notionのクエリ結果から必要な情報を抽出する\n",
        "\n",
        "    Args:\n",
        "        results (dict): Notionのクエリ結果\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: 抽出された記事情報のリスト\n",
        "    \"\"\"\n",
        "    news_list = []\n",
        "    for result in results[\"results\"]:\n",
        "        properties = result[\"properties\"]\n",
        "\n",
        "        # 必要な情報を抽出\n",
        "        news_info = {\n",
        "            'tag': properties[\"tag\"][\"select\"][\"name\"],\n",
        "            'title': properties[\"name\"][\"title\"][0][\"text\"][\"content\"],\n",
        "            'url': properties[\"URL\"][\"url\"],\n",
        "            'summary': \"\" if not properties[\"summary\"][\"rich_text\"] else\n",
        "                      properties[\"summary\"][\"rich_text\"][0][\"text\"][\"content\"]\n",
        "        }\n",
        "        news_list.append(news_info)\n",
        "\n",
        "    return news_list\n",
        "\n",
        "def group_news_by_tag(news_list: List[Dict]) -> Dict[str, List[Dict]]:\n",
        "    \"\"\"\n",
        "    ニュース記事をタグごとにグループ化する\n",
        "\n",
        "    Args:\n",
        "        news_list (List[Dict]): ニュース記事のリスト\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, List[Dict]]: タグでグループ化されたニュース記事\n",
        "    \"\"\"\n",
        "    grouped_news = defaultdict(list)\n",
        "    for news in news_list:\n",
        "        grouped_news[news['tag']].append(news)\n",
        "\n",
        "    # タグでソート\n",
        "    return dict(sorted(grouped_news.items()))\n",
        "\n",
        "def format_news_output_for_monthly_summary(grouped_news: Dict[str, List[Dict]]) -> str:\n",
        "    \"\"\"\n",
        "    グループ化されたニュースを指定された形式でフォーマットする\n",
        "\n",
        "    Args:\n",
        "        grouped_news (Dict[str, List[Dict]]): タグでグループ化されたニュース記事\n",
        "\n",
        "    Returns:\n",
        "        str: フォーマットされたニュース記事テキスト\n",
        "    \"\"\"\n",
        "    output = []\n",
        "    for tag, news_items in grouped_news.items():\n",
        "        output.append(f\"### 【{tag}】\")\n",
        "        for news in news_items:\n",
        "            output.extend([\n",
        "                f\"#### 〇 {news['title']}\",\n",
        "                news['url'],\n",
        "                news['summary'] if news['summary'] else \"\",\n",
        "                \"\"  # 記事間の空行\n",
        "            ])\n",
        "        output.append(\"\")  # タグセクション間の空行\n",
        "\n",
        "    return \"\\n\".join(output)\n",
        "\n",
        "def main_for_monthly_report(url: str, headers: dict) -> str:\n",
        "    \"\"\"\n",
        "    メイン処理関数\n",
        "\n",
        "    Args:\n",
        "        url (str): NotionのAPIエンドポイント\n",
        "        headers (dict): APIリクエストヘッダー\n",
        "\n",
        "    Returns:\n",
        "        str: フォーマットされたニュース記事テキスト\n",
        "    \"\"\"\n",
        "    # flagがpickの記事を取得\n",
        "    results = pick_daily_news_from_database(url, headers)\n",
        "\n",
        "    # 記事情報を抽出\n",
        "    news_list = extract_news_from_results(results)\n",
        "\n",
        "    # タグでグループ化\n",
        "    grouped_news = group_news_by_tag(news_list)\n",
        "\n",
        "    # 指定された形式でフォーマット\n",
        "    formatted_output = format_news_output_for_monthly_summary(grouped_news)\n",
        "\n",
        "    return formatted_output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ニュースまとめ記事の作成"
      ],
      "metadata": {
        "id": "VlGbZIpO2V_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickup_type = \"day\"\n",
        "title_date = \"2025-04-18\"\n",
        "title_name = \"\"\n",
        "\n",
        "# Notionデータベースからflag='true'でpickup_typeに合致するものを抽出\n",
        "news_contents = main(pickup_type, title_date, title_name)\n",
        "\n",
        "# Claude APIを使って、ニュースの要約・整形、ブログタイトル、ブログの感想を作成\n",
        "news_summary, news_title, news_impression = process_all_news(news_contents)\n",
        "\n",
        "# noteに貼り付ける用の整形\n",
        "formatted_result = format_news_articles_for_note(news_summary)\n",
        "\n",
        "# マークダウン形式で結果を出力（出力結果をnoteにコピペすればOK）\n",
        "display_news_markdown(\n",
        "    news_title=news_title,\n",
        "    news_impression=news_impression,\n",
        "    formatted_result=formatted_result\n",
        ")"
      ],
      "metadata": {
        "id": "KrAsNzVMCGxm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce7e8789-9ff6-4383-a575-80ea52189391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# 「Gemini 2.5 Flash」思考プロセス搭載、「FramePack」「Wan」動画生成AI進化、Huawei「CloudMatrix 384」NVIDIAを上回る性能、OpenAI「Codex CLI」公開、中国AIモデル米国に追随、PLaMoの日本語埋め込みモデル｜4月18日のIT・AIニュースピックアップ！\n\nこんにちは、MOFUです。\n\nGoogleが開発者向けに「Gemini 2.5 Flash」を早期公開しました。このモデルは複雑な課題を分解して応答を計画できる思考プロセス機能を搭載しており、主要AIモデルと同等の性能を維持しながらもコンパクトで低コストな運用を実現しています。開発者は用途に応じて柔軟な設定ができるようになっており、AIの実用性と経済性を両立させる新たな選択肢として期待できそうですね。\n\n動画生成AIの分野では「FramePack」という新手法が登場しました。入力コンテキストを一定の長さに圧縮する特徴により、動画の長さに関係なく一定の処理負荷で生成できるのが特徴です。13Bという大規模モデルでもノートPCのGPUで処理できる実用性の高さは、クリエイターの間で広く活用される可能性を秘めていますね。\n\nさらに動画生成AIの新モデル「Wan」も発表されました。時空間の因果性を考慮した設計と特徴量キャッシュの導入により、大規模モデルではOpenAIの「Sora」を超える性能を実現する可能性があるとのこと。小規模モデルでもGPUメモリ使用量を抑えた効率的な設計を採用しており、動画生成AIの民主化が一歩進んだように感じます。\n\nハードウェア面では、Huaweiが新AIアーキテクチャ「CloudMatrix 384 Supernode」を発表しました。384個のAscend 910Cチップを搭載し、NVIDIAのGB200 NVL72と比べて1.7倍の性能を実現しているとのこと。ただし消費電力は3.9倍と効率面での課題も残されています。中国製AIハードウェアの急速な進化は、グローバルなAI開発競争をさらに加速させそうです。\n\nOpenAIは自然言語でシェルコマンドを実行できるコーディングエージェント「Codex CLI」をオープンソースで公開しました。Node.js製のこのツールは、ユーザーの自然言語指示からシェルコマンドを生成・実行できる便利な機能を提供しています。プログラミングの敷居をさらに下げる取り組みとして、多くの開発者に歓迎されるでしょう。\n\nスタンフォード大学のAIインデックス調査によると、中国と米国の主要なAIモデルの性能差が大幅に縮小し、ほぼ同等の水準に達していることが明らかになりました。2024年の注目すべきAIモデル開発件数では、米国が40件、中国が15件を記録。AI開発における二大国の競争は今後も続き、技術革新のペースがさらに加速しそうです。\n\n国内では、Preferred Networksが日本語に特化したローカル実行可能な新テキスト埋め込みモデル「PLaMo-Embedding-1B」を公開しました。ローカル環境で動作し、高性能な日本語テキストの埋め込みが可能な特徴を持ち、工場内でのデータ検索など、セキュアな環境での活用が期待されています。日本語処理に特化したAIモデルの充実は、国内企業のAI活用を大きく後押しするでしょう。\n\n### Google、思考プロセスを備えた新型AI「Gemini 2.5 Flash」を開発者向けに早期公開\n\n【新しいLLM】Googleが新たに公開したGemini 2.5 Flashは、複雑な課題を分解して応答を計画できる思考プロセス機能を搭載しています。この新機能により、他の主要なAIモデルと同等の性能を維持しながら、よりコンパクトで低コストな運用を実現しました。開発者は用途に応じて柔軟な設定が可能となっています。\n\nhttps://developers.googleblog.com/en/start-building-with-gemini-25-flash/\n\n\n### MongoDBとMCPの組み合わせが従来のRAG方式を超える可能性を示唆する新技術動向\n\n【技術解説】MongoDBとMCPサーバーを組み合わせることで、JSON形式のデータに対してナチュラルな質問による効率的な検索が可能になっています。ただし、大量データの検索時にはトークン消費の増加やクライアントのフリーズに注意が必要です。この技術の発展により、従来のRAG方式に代わる新しいデータ検索手法として期待が高まっています。\n\nhttps://zenn.dev/wooheum/articles/54adee2a91c26a\n\n\n### OpenAI、自然言語でシェルコマンドを実行できるコーディングエージェント「Codex CLI」をオープンソースで公開\n\n【技術解説】OpenAIが新たにリリースしたCodex CLIは、Node.js製のコーディングエージェントツールで、ユーザーの自然言語指示からシェルコマンドを生成・実行できます。独自のMarkdown風DIFF書式を採用し、OpenAI Responses APIと連携してソースコードの編集を可能にしています。\n\nhttps://blog.lai.so/openai-codex/\n\n\n### 動画生成AIの新手法「FramePack」が登場、ノートPCでも効率的な動画生成が可能に\n\n【動画生成AI】効率的な次フレーム予測の新しいニューラルネットワーク構造「FramePack」が公開されました。入力コンテキストを一定の長さに圧縮する特徴により、動画の長さに関係なく一定の処理負荷で動画を生成できます。13Bという大規模なモデルでもラップトップのGPUで処理が可能な実用性の高い技術です。\n\nhttps://github.com/lllyasviel/FramePack\n\n\n### 動画生成AIの新モデル「Wan」が登場、Soraを上回る性能と効率的な設計を実現\n\n【動画生成AI】新しい大規模ビデオ生成モデル「Wan」が発表されました。時空間の因果性を考慮した設計と特徴量キャッシュの導入により、大規模モデルではOpenAIのSoraを超える性能を実現する可能性があります。また、小規模モデルでもGPUメモリ使用量を抑えた効率的な設計を採用しており、実用性の高いモデルとなっています。\n\nhttps://blog.shikoan.com/wan/?utm_source=feedly&utm_medium=rss&utm_campaign=wan\n\n\n### デジタル庁の自動配送ロボット実証実験で安全課題が浮上、エレベーター挟まれ事故も発生\n\n【ロボット・ドローン】デジタル庁が実施した自動配送ロボットの実証実験において、ロボット同士の接触やエレベーターでの挟まれ事故などの安全上の課題が明らかになりました。この結果を受けて、複数ロボットの安全な走行のための事業者間協調と共通ルールの整備を進めることが決定し、ロボットフレンドリー施設推進機構との連携も予定されています。\n\nhttps://jidounten-lab.com/u_53902\n\n\n### Huaweiが新AIアーキテクチャ「CloudMatrix 384」を発表、384個のチップ搭載でNVIDIA製品を性能で上回る\n\n【ハードウェア】Huaweiが新たに発表したAIインフラアーキテクチャ「CloudMatrix 384 Supernode」は、384個のAscend 910Cチップを搭載し、NVIDIAのGB200 NVL72と比べて1.7倍の性能を実現しています。ただし消費電力は3.9倍と効率面での課題が残されています。すでに中国安徽省のデータセンターに設置され、中国製の推論モデルにも対応しています。\n\nhttps://gigazine.net/news/20250418-huawei-ai-cloudmatrix-384-supernode/\n\n\n### AIエージェントのみで構成されたSNSでは人間よりも誤情報の拡散が少ないことが研究で判明\n\n【AI】研究者たちが「MOSAIC」というシミュレーションを使用して、AIだけのSNS環境を分析した結果が発表されました。人間が使用する実際のSNSと比較して、AIエージェントは誤情報の拡散を抑制する傾向が確認され、ファクトチェックも効果的に機能することが分かりました。また、投稿の人気度は内容そのものよりもシステムの設計に大きく影響されることも明らかになっています。\n\nhttps://www.itmedia.co.jp/aiplus/articles/2504/18/news074.html\n\n\n### AI研究者向けスキルアップ研修の資料を公開、コードレビューからライセンスまで幅広い技術テーマを網羅\n\n【スキルアップ】AI Labが研究者向けに実施したスキルアップ研修の資料を公開しました。研修では、コードレビュー、ライセンス、図の作成など研究に必要な技術テーマを幅広く取り上げ、参加者から高い評価を得ています。オンライン・オフライン共に多くの参加があり、今後は参加者の技術レベルに応じた内容の最適化を目指します。\n\nhttps://cyberagent.ai/blog/research/20228/\n\n\n### Preferred Networksが日本語に特化したローカル実行可能な新テキスト埋め込みモデル「PLaMo-Embedding-1B」を公開\n\n【AI】Preferred Networksが開発した日本語テキスト埋め込みモデル「PLaMo-Embedding-1B」が注目を集めています。ローカル環境で動作し、高性能な日本語テキストの埋め込みが可能な特徴を持ち、工場内でのデータ検索など、セキュアな環境での活用が期待されています。\n\nhttps://dev.classmethod.jp/articles/shuntaka-try-plamo-embedding-1b/\n\n\n### AIを活用した効率的な開発手法「Vibe Coding」の実践例：チャットAIとの対話から実装までの個人開発フロー\n\n【つくってみた・やってみた】個人開発において、チャットAIを活用して要件定義から技術選定、実装までを効率的に進める「Vibe Coding」の実践方法が紹介されています。AIとの対話を通じて開発を進めながらも、Gitによるバージョン管理は人間が担当するなど、AIと人間の役割分担を明確にした開発スタイルが確立されています。\n\nhttps://zenn.dev/yoshiko/articles/my-vibe-coding\n\n\n### MITが開発、プログラミング言語の仕様に合わせてAIコード生成を最適化する新技術\n\n【LLM新技術】MITの研究チームが、大規模言語モデルの出力を各プログラミング言語の仕様に自動的に適合させる新手法を開発しました。この技術により、小規模なLLMでも高精度なコード生成が可能となり、プログラミングアシスタントやデータ分析ツールなどへの幅広い応用が期待されています。\n\nhttps://news.mit.edu/2025/making-ai-generated-code-more-accurate-0418\n\n\n### スタンフォード大学の調査で中国のAIモデル性能が米国に追いつき、両国の技術格差が縮小傾向に\n\n【LLMの評価】スタンフォード大学のAIインデックス調査によると、中国と米国の主要なAIモデルの性能差が大幅に縮小し、ほぼ同等の水準に達していることが明らかになりました。2024年の注目すべきAIモデル開発件数では、米国が40件、中国が15件を記録し、両国の主要企業が上位を占めています。\n\nhttps://36kr.jp/341424/\n\n\n### LLMを活用した実用的なAIエージェント開発のための12の原則が公開、本番環境での運用指針を提示\n\n【AIエージェント】LLMを活用したAIエージェントを実際の本番環境で運用するための12の原則がGitHubで公開されました。この原則では、LLMの能力を最大限に活用しながらも、完全な自動化ではなく適切な人間の管理と制御の重要性を強調しています。\n\nhttps://github.com/humanlayer/12-factor-agents\n\n\n### AIエージェント開発の4要素：設計と実装における重要ポイントと課題を解説\n\n【AIエージェント】AIエージェントの開発において、「instruction」「language model」「memory」「tools」という4つの重要な要素に基づいた設計・実装の知見が紹介されています。自律性と制御性のバランス、効果的なテスト方法、個性的なUXの実現など、実践的な課題とその対応策について解説されています。\n\nhttps://zenn.dev/aishift/articles/6aa1540ea27fcd\n\n\n### 小田急電鉄、IR業務効率化に向けて生成AI「exaBase IRアシスタント」を導入し業務DXを推進\n\n【AIの活用】小田急電鉄がIR部門の業務効率化を目指し、生成AI「exaBase IRアシスタント」を導入することを発表しました。この取り組みにより、IR部門は定型的な業務から解放され、より付加価値の高い情報開示や投資家との対話に注力できる体制の構築を目指します。サービスを提供するExa Enterprise AIは、生成AI技術を通じて日本企業の生産性向上を支援しています。\n\nhttps://robotstart.info/2025/04/18/odakyu-introduce-ai-ir-service.html\n\n\n### 声優・梶裕貴さんのオリジナルキャラクター「そよぎ」がAI会話アプリ「HAPPY RAT」に登場、新たな物語体験を提供\n\n【AIの活用】SpiralAIが提供する会話型友だちAIアプリ「HAPPY RAT」に、人気声優・梶裕貴さんが手がけるオリジナルコンテンツ「そよぎフラクタル」のキャラクターが登場することになりました。未来からやってきたネズミ型アンドロイド「そよぎ」との対話を通じて、ユーザーは新たな物語体験を楽しむことができます。\n\nhttps://robotstart.info/2025/04/18/happy-rat-colabo-soyogi-fractal.html\n\n\n### 生成AIが訴状から裁判の勝訴確率を予測し法的アドバイスを提供する新サービスをリーガルAIが開発\n\n【AIの活用】リーガルAIが、訴状の内容をAIで分析し裁判の結果を予測する新サービスを開発しました。AIが法律や過去の判例データベースを活用して事実認定や法令解釈を行い、ユーザーに判決の見通しを提示することで、訴訟に関する意思決定をサポートします。\n\nhttps://www.nikkei.com/article/DGXZQOUC10BSJ0Q5A410C2000000/\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 特定のニュースをピックアップしたい場合\n",
        "pickup_type = \"day\"\n",
        "title_date = \"\"\n",
        "title_name = \"わくわくAIニュース\"\n",
        "\n",
        "# Notionデータベースからflag='true'でpickup_typeに合致するものを抽出\n",
        "news_contents = main(pickup_type, title_date, title_name)"
      ],
      "metadata": {
        "id": "lwVgg4DbyvUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# カテゴリごとに整理\n",
        "NOTION_API_KEY = userdata.get('NOTION_API_KEY')\n",
        "DATABASE_ID = userdata.get('PICKUP_DATABASE_KEY')\n",
        "\n",
        "url = f'https://api.notion.com/v1/databases/{DATABASE_ID}/query'\n",
        "headers = {\n",
        "    'Notion-Version': '2022-06-28',\n",
        "    'Authorization': f'Bearer {NOTION_API_KEY}',\n",
        "    'Content-Type': 'application/json',\n",
        "}\n",
        "\n",
        "formatted_news = main_for_monthly_report(url, headers)\n",
        "print(formatted_news)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G91G3nPG44xK",
        "outputId": "369a8835-70c5-4c46-9fdd-f0f0ca4228ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 【AIと人間の未来】\n",
            "#### 〇 AIエージェントにホテルを予約させる実験から判明した衝撃の事実、AIはオンライン広告をどう見ているのか？ 【生成AI事件簿】構造化データを好むAIエージェントにバナー広告やブランド広告は不適か | JBpress (ジェイビープレス)\n",
            "https://jbpress.ismedia.jp/articles/-/87753?page=2\n",
            "従来のAPIによる連携に代わり、AIエージェントがブラウザを直接操作できるようになったことで、ウェブサイトの管理者には「GAIO（生成AI最適化）」と呼ばれる新たな対応が必要になってきている。また、この傾向を受けて、AIエージェントに効果的なオンライン広告の在り方について、構造化されたデータの重視やキーワードマッチングの重要性が指摘されている。\n",
            "\n",
            "#### 〇 再犯防止と更生支援のために開発されたアルゴリズム「TIGER」が受刑者の仮釈放資格を判断する唯一の基準となってしまっている\n",
            "https://gigazine.net/news/20250415-tiger-algorithm/\n",
            "ルイジアナ州は、2014年に開発した再犯防止アルゴリズム「TIGER」を使って、受刑者の仮釈放を判断するようになりました。しかし、TIGERスコアが唯一の基準となり、受刑者の更生状況にかかわらず仮釈放を拒否することが問題視されています。専門家からは、過去の情報にのみ依存するTIGERの問題点が指摘されています。\n",
            "\n",
            "#### 〇 “AIが95％ 芥川賞作家が5％書いた小説” 雑誌に掲載 | NHK\n",
            "https://www3.nhk.or.jp/news/html/20250325/k10014759151000.html\n",
            "芥川賞作家の九段理江さんと生成AIが共同で執筆した小説「影の雨」が、雑誌に掲載されました。この作品は、人間の記憶や感情の痕跡を辿りながら、「感情とは何のためにあるのか」を探究するという内容の短編小説です。九段さんは全体の5％を担当し、冒頭と文末の修正を行った一方で、95％はAIが執筆したものです。九段さんは、この経験を通して、人間がフィクションを想像する本質的な意味について考え直す機会となったと述べています。\n",
            "\n",
            "#### 〇 ChatGPTの使用が感情的な幸福にどのように影響するかに関する初の研究をOpenAIがMITと協力して発表\n",
            "https://gigazine.net/news/20250324-openai-affective-use-study/\n",
            "OpenAIとMITメディアラボが共同で、ChatGPTの使用が人々の感情的な幸福に及ぼす影響について研究を行いました。研究チームは、ChatGPTのインタラクションを自動分析するとともに、ユーザーを対象とした調査を行い、感情的な利用傾向や心理社会的影響について明らかにしました。その結果、短時間の音声利用は幸福感を高めるものの、長時間の使用は幸福感を低下させることなどが判明しました。研究チームは、今回の結果をもとに、人工知能システムと人間の相互作用についてさらなる分析が必要だと述べています。\n",
            "\n",
            "\n",
            "### 【AIの活用】\n",
            "#### 〇 AIが教科書に沿って個別に最適な学習支援 東京書籍の次世代学習サービス「教科書AI ワカル」にオルツの生成AI基盤を採用 - ロボスタ ロボスタ - ロボット情報WEBマガジン\n",
            "https://robotstart.info/2025/04/17/altbrain-tokyoshoseki.html\n",
            "東京書籍が開発した「教科書AI ワカル」サービスに、オルツ社が提供する大規模言語モデル「LHTM-2」を基盤としたノーコード生成AIプラットフォーム「altBrain」が採用されました。「教科書AI ワカル」は学習者一人ひとりの理解度や学習ペースに合わせて最適な学習体験を提供する、AI対話型の新しい学習サービスです。\n",
            "この新サービスは、授業と完全に連動しているため、日々の学習の延長として安心して活用できます。また、AIとの対話を通じて学習者自身が主体的に考え、深く学ぶことができるとしています。今後は機能強化を重ね、幅広い学習者への支援を目指していきます。\n",
            "\n",
            "#### 〇 中国、法務現場に「AIエージェント」 契約審査を半分の時間に | 36Kr Japan | 最大級の中国テック・スタートアップ専門メディア\n",
            "https://36kr.jp/337991/\n",
            "中国の電子署名大手「法大大」が、独自の大規模言語モデルを基盤とした法務AIエージェント「iTerms Pro」を発表しました。iTerms Proは、契約書の自動審査やモニタリング、法律リサーチ、コンプライアンス対応などを行える機能を有しており、企業の法務担当者の業務効率向上を目指しています。法大大は、AIが広く活用されるようになったことで企業との協業にも意欲的になっており、今後は法務分野でのAI活用が進むと見られています。\n",
            "\n",
            "#### 〇 DolphinGemma: How Google AI is helping decode dolphin communication\n",
            "https://deepmind.google/discover/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/\n",
            "長年にわたり、イルカの鳴き声やホイッスル、バースト音声の解読は科学的な最前線でしたが、Google、ジョージア工科大学、ワールド・ドルフィン・プロジェクト (WDP) の研究者らが共同で開発したDolphinGemmaというAIモデルにより、イルカの自然な意思疎通を分析し、理解を深めることが期待されています。また、WDPが進める「CHAT」システムを通じて、人とイルカが双方向で交流できる仕組みづくりにも取り組んでいます。\n",
            "\n",
            "#### 〇 Google、イルカのコミュニケーション解読を目指すAIモデル「DolphinGemma」発表 - ITmedia NEWS\n",
            "https://www.itmedia.co.jp/news/articles/2504/15/news103.html\n",
            "グーグルが、イルカのコミュニケーションを解読するための新しいLLM「DolphinGemma」を発表しました。また、研究者たちがイルカとの簡単な言語を用いたコミュニケーションを可能にする「CHAT」システムの開発も進めています。グーグルはDolphinGemmaを今夏にオープンモデルとして公開する予定で、様々な種類のイルカの研究に活用されることが期待されています。\n",
            "\n",
            "#### 〇 Repurposing Protein Folding Models for Generation with Latent Diffusion – The Berkeley Artificial Intelligence Research Blog\n",
            "http://bair.berkeley.edu/blog/2025/04/08/plaid/\n",
            "PLAIDは、タンパク質の機能と構造を制御可能な生成モデルです。従来のタンパク質生成モデルには実用的な課題がありましたが、PLAIDではタンパク質の構造情報を活用することで、機能と構造を両立させた生成が可能となりました。また、単一のテキストプロンプトによりタンパク質の機能と生物種を指定できる点が特徴的です。\n",
            "\n",
            "#### 〇 Microsoftがリアルタイムでゲームを生成するAIモデル「WHAMM」をリリース、「Quake II」を使ったデモもプレイ可能\n",
            "https://gigazine.net/news/20250407-microsoft-ai-quake-2-demo/\n",
            "Microsoft は、プレイヤーの操作に即座に反応し、ゲーム環境を生成できる新しいAIモデル「WHAMM」を発表しました。このAIモデルは従来のものに比べて、リアルタイムな描写が可能となり、Quake II のデモでも実際にプレイできるようになりましたが、まだ課題も残されています。Microsoft は、このWHAMMモデルが新しいインタラクティブメディアの可能性を示すものだと述べています。\n",
            "\n",
            "#### 〇 AIロボットが人生を共に楽しむパートナー 認知症の対策、健康寿命の延伸、クウジットが「Active Aging Platform」を開発 - ロボスタ ロボスタ - ロボット情報WEBマガジン\n",
            "https://robotstart.info/2025/03/24/koozit-active-aging-platform.html\n",
            "クウジットは「Active Aging Platform」を開発し、音声対話型AIパートナーを通じて高齢者のウェルビーイングを高めることを目指している。このAIパートナーは、高齢者の趣味や関心事をパーソナライズした対話を行い、認知機能の維持・向上に貢献する。また、離れて暮らす家族とのコミュニケーションを促進し、高齢者の社会参加を支援することで、フレイルの予防に役立つプラットフォームを目指している。\n",
            "\n",
            "#### 〇 AIを使い一般的なデスクトップPCでも動作するAI天気予報システム「Aardvark Weather」、従来より数千倍少ない計算能力ではるかに高速\n",
            "https://gigazine.net/news/20250324-aardvark-weather-prediction/\n",
            "ケンブリッジ大学の研究チームが開発した「Aardvark Weather」は、人工衛星などのデータを取り込んで迅速かつ正確な天気予報を行える新しいシステムです。従来の天気予報システムと比べて、計算能力が数千分の1で済み、スーパーコンピューターを必要としません。今後は、ハリケーンや山火事などの予報にも応用が期待されています。\n",
            "\n",
            "#### 〇 AIに欠かせない機械学習の手法を物理学に融合させる新しい概念「学習物理学」とはどういうものか？ - 大学ジャーナルオンライン\n",
            "https://univ-journal.jp/column/2025252175/\n",
            "AIの急速な進化により、著作権問題やプライバシー保護、教育の変化など、さまざまな社会課題が喫緊の問題となっている中、物理学者の橋本先生は「学習物理学」という新しい取り組みを提唱しています。この分野では、機械学習と物理学の融合により、基礎物理学の変革を目指しており、AIが物理学の研究を加速させる可能性について言及しています。また、AIと物理学の融合により、物質と精神の関係性についての新たな知見が得られるかもしれないと述べています。\n",
            "\n",
            "\n",
            "### 【AIエージェント】\n",
            "#### 〇 ［速報］Google Cloudが複数のAIエージェントを連携させる「Agent2Agentプロトコル」を発表。50社以上がサポートを表明\n",
            "https://www.publickey1.jp/blog/25/google_cloudaiagent2agent50.html\n",
            "Google Cloudは、異なるベンダーやフレームワークで構築されたエージェント同士がセキュリティを保ちつつ連携できる「Agent2Agentプロトコル」を発表しました。これにより、開発者はマルチエージェントシステムを構築できるようになります。また、プロトコルの基盤に広く利用されている標準を採用しているため、既存のITシステムとの統合が容易であり、セキュアな認証と認可を実現します。\n",
            "\n",
            "\n",
            "### 【DL新技術】\n",
            "#### 〇 A faster way to solve complex planning problems\n",
            "https://news.mit.edu/2025/faster-way-solve-complex-planning-problems-0416\n",
            "機械学習を活用することで、従来のアプローチよりも50%以上の解決時間短縮と21%の解決精度向上を実現した新しい最適化手法が開発されました。この手法は、通勤電車の運転計画や工場の生産スケジューリングなど、複雑な組合せ最適化問題に対して適用可能で、柔軟性も高いことが特徴です。今後は、モデルの判断ロジックの解明や他の最適化問題への応用など、さらなる発展が期待されています。\n",
            "\n",
            "\n",
            "### 【LLMの性質】\n",
            "#### 〇 大規模言語モデルは内部で 何をやっているのか？ 覗いて分かった奇妙な回路\n",
            "https://www.technologyreview.jp/s/358515/anthropic-can-now-track-the-bizarre-inner-workings-of-a-large-language-model/\n",
            "アンソロピック社の研究チームは、大規模言語モデル(LLM)の内部構造を可視化し、その動作メカニズムについて新たな知見を得ることに成功しました。研究の結果、LLMは私たちが想像していた以上に複雑で不可解な存在であることが明らかになりました。LLMの仕組みを解明することは科学界の重要な課題の一つであり、その内部構造を追跡する技術は大きな進歩を遂げたといえます。\n",
            "\n",
            "\n",
            "### 【LLMの評価】\n",
            "#### 〇 「逆転裁判」でOpenAI-o1、Gemini 2.5 Pro、Claude 3.7 Sonnet、Llama-4 Maverickの推論能力を検証する\n",
            "https://gigazine.net/news/20250417-ai-plays-ace-attorney/\n",
            "カリフォルニア大学サンディエゴ校のHao Zhang教授率いるHao AI Labが、OpenAIの元主任科学者の指摘を受けて、探偵ゲーム「逆転裁判」をAIモデルに挑ませた。4つのAIモデルに挑戦させた結果、OpenAI o1が最後まで進めたものの、コストパフォーマンスを考慮するとGemini 2.5 Proが高く評価されている。Hao AI Labは他のゲームベンチマークも行っており、その結果をHugging Faceで公開している。\n",
            "\n",
            "#### 〇 OpenAIがAIのウェブ検索能力を測定する高難度ベンチマーク「BrowseComp」を発表\n",
            "https://gigazine.net/news/20250411-openai-browsecomp-benchmark-browsing-agent/\n",
            "OpenAIは、ウェブ検索能力を測るベンチマーク「BrowseComp」を開発しました。このベンチマークは、人間の回答例に基づいた高難度な問題を1,266問含んでおり、正解を導き出すのは困難ですが、ウェブ検索によってその正否を確認できます。人間がこの問題を解いた結果、29.2%の問題を2時間以内に回答できましたが、正答率は86.4%と高い水準でした。一方、OpenAIのAIモデルでは最高でも51.5%の正答率にとどまり、ウェブ検索能力の評価に有効なベンチマークであることが示されました。\n",
            "\n",
            "#### 〇 PaperBench: Evaluating AI’s Ability to Replicate AI Research\n",
            "https://openai.com/index/paperbench\n",
            "新しいベンチマーク「PaperBench」は、最先端のAI研究論文を複製する能力を評価します。20編のICML 2024論文の理解から、コードベースの開発、実験の実行までを対象とし、詳細な採点基準に基づいて評価されます。自動採点システムも開発されましたが、現時点では人間の専門家にも及ばない成績にとどまっています。\n",
            "\n",
            "#### 〇 主要AIモデルはどれも“歯が立たない”、新しい「人間には簡単だがAIには難しいAGI問題」登場（生成AIクローズアップ） | テクノエッジ TechnoEdge\n",
            "https://www.techno-edge.net/article/2025/03/31/4224.html\n",
            "ARC Prize財団は、AGI(汎用人工知能)の進化を測るため、より難易度の高い新しいベンチマークテスト「ARC-AGI-2」を発表しました。従来の「ARC-AGI-1」に比べ、最先端のAIモデルでも一桁台のパーセンテージしか達成できない非常に難しいテストとなっています。ARC-AGI-2では、記号的解釈、構成的推論、文脈依存のルール適用といった能力が特に重要とされており、人間には容易だがAIにはまだ難しい課題となっています。また、効率性の指標としてコストも評価されるようになり、AIの能力と効率性の両面が重要視されるようになってきています。\n",
            "\n",
            "\n",
            "### 【LLM新技術】\n",
            "#### 〇 Training LLMs to self-detoxify their language\n",
            "https://news.mit.edu/2025/training-llms-self-detoxify-their-language-0414\n",
            "大規模言語モデルは、インターネットなどから収集したデータに基づいて訓練されるため、有害な言語も学習する可能性があります。MIT、IBM Watson AI Lab、IBMの研究チームは、大規模言語モデルの出力を毒性のある言語から防ぐ新しい手法を開発しました。この手法は、モデルのパラメータを変更することなく、生成プロセス中にリアルタイムで有害な言語を検出し、避けるというものです。この手法は、言語モデルの流暢性を損なうことなく、有害な言語の生成を大幅に削減することができます。\n",
            "\n",
            "\n",
            "### 【MCP】\n",
            "#### 〇 GitHub - github/github-mcp-server: GitHub's official MCP Server\n",
            "https://github.com/github/github-mcp-server\n",
            "GitHub MCP サーバーはGitHubのクラウドサービスを利用したサーバーで、ツールの一括インストールや設定、多言語化などの機能を提供しています。サーバーの利用にはGitHubアクセストークンが必要で、VS Codeの統合や自動インストール、設定ファイルでの詳細な設定が可能です。\n",
            "\n",
            "#### 〇 GitHub - conorbranagan/mcp-openapi: Bridge for AI agents to interact with OpenAPI endpoints via MCP\n",
            "https://github.com/conorbranagan/mcp-openapi\n",
            "MCP-OpenAPI Server は、既存の API エンドポイントを AI エージェントが発見・操作できるようにするブリッジです。大規模な OpenAPI 仕様ファイルを扱う際、初回の起動時には処理に時間がかかりますが、ディスクにキャッシュすることで、その後の起動は高速になります。また、サーバーの設定や動作確認、カスタム統合のための機能も提供されています。\n",
            "\n",
            "#### 〇 Microsoft Playwright MCPが切り拓くLLMとブラウザの新たな統合\n",
            "https://zenn.dev/kimkiyong/articles/679faf454b0ee0\n",
            "マイクロソフトの「Playwright MCP」は、大規模言語モデル(LLM)とウェブブラウザの統合を実現する革新的な技術です。アクセシビリティツリーを活用した効率的かつ信頼性の高いブラウザ自動化を可能にし、ウェブテスト、データ収集、カスタマーサポート、コンテンツ管理など、様々な分野での活用が期待されています。この技術は、AI とウェブ技術の融合を推進し、デジタル体験のあり方を根本的に変えていくことが期待されています。\n",
            "\n",
            "\n",
            "### 【OpenAI】\n",
            "#### 〇 OpenAI、約30億ドルで「Windsurf」買収を交渉中――Bloomberg報道 - ITmedia NEWS\n",
            "https://www.itmedia.co.jp/news/articles/2504/17/news125.html\n",
            "OpenAIが、AI支援によるコーディングツール「Windsurf」の買収に向けて約30億ドルの協議を行っていることが報じられました。この買収はOpenAIの過去最大規模となる見通しですが、契約条件はまだ確定しておらず、交渉の結果が変更あるいは破談となる可能性もあります。一方で、投資家との資金調達で企業評価額30億ドルを目指しているWindsurfは、この買収交渉の最中にあるといわれています。\n",
            "\n",
            "#### 〇 Thinking with images\n",
            "https://openai.com/index/thinking-with-images\n",
            "OpenAIの新しいモデルo3とo4-miniは、画像を使った思考能力の大幅な向上を実現しました。これらのモデルは、画像を加工・分析しながら長期的な推論を行うことで、より高度な多様な問題解決を可能にしています。特に、写真やスクリーンショットを活用して、経済問題の解説や技術的な分析など、視覚情報と文章情報を組み合わせた高度な推論が行えるようになっています。\n",
            "\n",
            "#### 〇 ChatGPTに「ライブラリ」新設　過去に生成した画像を一覧 - ITmedia NEWS\n",
            "https://www.itmedia.co.jp/news/articles/2504/16/news149.html\n",
            "OpenAIは、「ChatGPT」に「ライブラリ」機能を追加しました。無料ユーザーにも提供されており、Webやモバイルから過去に生成した画像を閲覧・編集することができるようになりました。ただし、現時点では画像の削除機能はないようです。\n",
            "\n",
            "#### 〇 GPT 4.1 Prompting Guide | OpenAI Cookbook\n",
            "https://cookbook.openai.com/examples/gpt4-1_prompting_guide\n",
            "GPT-4.1はGPT-4oから大幅な機能向上を遂げており、コーディング、命令の理解、長文コンテキストの処理などの能力が飛躍的に向上しています。本ガイドでは、GPT-4.1の改善された機能を最大限に引き出すための重要なプロンプティングのヒントを提示しています。特に、より具体的で明確な命令の提示、計画的なプロンプティング、ツールの効果的な活用などを推奨しており、これらの対策によって、GPT-4.1モデルの性能を大幅に引き上げることができます。\n",
            "\n",
            "\n",
            "### 【つくってみた・やってみた】\n",
            "#### 〇 LLMによるパワポ自動生成にチャレンジしてわかった課題 - Insight Edge Tech Blog\n",
            "https://techblog.insightedge.jp/entry/llm_pptx_challenges\n",
            "LLMを使ってPowerPointスライドを自動生成する取り組みについて紹介しています。PPTX形式は複雑な仕様を持つため、スライドレイアウトやプレースホルダーなどの制約に注意が必要であり、日本語対応にも課題があることが述べられています。また、LLMの出力をそのまま利用すると見づらい発表になる可能性があるため、文字数や文章の長さの制限が重要だと指摘しています。LLMを活用したPPTX自動生成には一定の工夫が必要であり、この記事はその知見を共有するものとなっています。\n",
            "\n",
            "\n",
            "### 【コーディング・開発支援AI】\n",
            "#### 〇 Open R1: How to use OlympicCoder locally for coding\n",
            "https://huggingface.co/blog/olympic-coder-lmstudio\n",
            "オープンソースのモデルであるOlympicCoderを活用することで、より簡単にAIを統合したIDEを構築できることが紹介されています。LMStudioを使えば、複雑な設定なしでHugging Faceのモデルをダウンロードして使うことができ、VSCodeとの連携も容易です。OlympicCoderは特定の課題に最適化されたモデルであるため、Claude等の汎用的なモデルと組み合わせることで、より幅広いニーズに対応できるようになります。\n",
            "\n",
            "\n",
            "### 【セキュリティ】\n",
            "#### 〇 CVE Foundationが発足。脆弱性に固有の番号を付与するCVEプログラムの長期的な安定性、独立性を確保\n",
            "https://www.publickey1.jp/blog/25/cve_foundationcve.html\n",
            "CVEプログラムを実行する新たな非営利団体「CVE Foundation」が発足しました。これまでCVEプログラムはMitre社が中心となって運営してきましたが、米国政府による資金提供の停止を受けて、プログラムの長期的な実行可能性、安定性、独立性を確保するため、新しい基金が設立されることになりました。CVE Foundationは、高品質の脆弱性識別を提供し、セキュリティ対策に取り組む世界中の人々にCVEデータの整合性と可用性を維持することを目指しています。\n",
            "\n",
            "#### 〇 Apple、プライバシーを保護しつつAI開発にユーザーデータを利用する方法を発表 - ITmedia NEWS\n",
            "https://www.itmedia.co.jp/news/articles/2504/15/news106.html\n",
            "Appleは、ユーザーのプライバシーを保護しつつ、機械学習やAIの機能を向上させるための技術「差分プライバシー」と「合成データ生成」を紹介しました。「差分プライバシー」は、ユーザーの特定の情報を収集せずに全体的な傾向を分析する仕組みです。一方、「合成データ生成」は、実際のユーザーデータを使わずに、似た特徴を持つ擬似的なデータを作り出すことで、機能の改善を行うものです。Appleは今後、これらの技術をさまざまな製品に導入し、ユーザーのプライバシーを守りながら機械学習の向上を目指していきます。\n",
            "\n",
            "#### 〇 Defending against Prompt Injection with Structured Queries (StruQ) and Preference Optimization (SecAlign) – The Berkeley Artificial Intelligence Research Blog\n",
            "http://bair.berkeley.edu/blog/2025/04/11/prompt-injection-defense/\n",
            "最近のLarge Language Model(LLM)の進化により、LLMを活用したアプリケーションが注目されています。しかし、LLMの改善に伴い、これらのシステムに対する攻撃も進化しており、特に「プロンプト・インジェクション」攻撃が問題になっています。研究チームは、構造化された学習手法「StruQ」と「SecAlign」を提案し、これらの攻撃に対する防御策を示しています。実験結果から、これらの手法が大幅にプロンプト・インジェクション攻撃を抑制できることが分かりました。\n",
            "\n",
            "\n",
            "### 【データセット】\n",
            "#### 〇 国土地理院、点群データをWeb地図上で見られる「点群タイル閲覧サイト」試験公開 - ITmedia NEWS\n",
            "https://www.itmedia.co.jp/news/articles/2503/31/news173.html\n",
            "国土地理院は、点群データを Web 地図で扱える形式に変換した「点群タイル」閲覧サイトの試験公開を始めました。この新しいサービスでは、計測時の写真と同じ色で立体的な表現が可能で、防災・減災への活用が期待されています。国土地理院は、この試験公開を通して、今後の安定的な運用に向けた課題を把握していく方針です。\n",
            "\n",
            "\n",
            "### 【ニュース】\n",
            "#### 〇 stanford-cme-295-transformers-large-language-models/ja at main · afshinea/stanford-cme-295-transformers-large-language-models\n",
            "https://github.com/afshinea/stanford-cme-295-transformers-large-language-models/tree/main/ja\n",
            "スタンフォード大学の CME 295 講座で扱う重要概念を集約したリポジトリが公開されました。この250ページにわたる書籍には、大規模言語モデルやTransformerに関する600点以上の図が収録されており、詳細はcme295.stanford.eduにてご確認いただけます。\n",
            "\n",
            "#### 〇 中国、“脳にチップ移植”3人成功　年内にさらに10人、人体での検証加速 - ITmedia NEWS\n",
            "https://www.itmedia.co.jp/news/articles/2503/31/news231.html\n",
            "中国の研究機関と企業が2025年末までに患者13人への脳チップ移植を目指していることがわかりました。この取り組みは世界最大規模のものとなる可能性があり、中国のBCI技術の向上への意欲が示されています。また、競合する米国企業との差別化を図るため、半侵襲型のチップの開発も進められています。\n",
            "\n",
            "\n",
            "### 【ロボット・ドローン】\n",
            "#### 〇 世界初「人型ロボット・マラソン」、北京で開催 21km激走で試される実力 | 36Kr Japan | 最大級の中国テック・スタートアップ専門メディア\n",
            "https://36kr.jp/336965/\n",
            "中国の北京亦荘（北京市の経済技術開発区）で、世界初となる人型ロボットのハーフマラソン競技が開催される。参加資格は二足歩行ロボットに限定され、ロボットの自律性や事前のプログラミングが認められている。競技の難易度は高く、ロボットの性能や持続時間が重要となるが、賞金は上位3位までの3000～5000元（約6～10万円）程度にとどまる。一方で、中国企業の人型ロボット開発は急速に進展しており、低価格化も進んでいる。このハーフマラソン大会は、人型ロボットの普及に向けた重要な一歩となりそうだ。\n",
            "\n",
            "\n",
            "### 【国内ニュース】\n",
            "#### 〇 ニューラルかな漢字変換システム「Zenzai」の開発 | さくらのナレッジ\n",
            "https://knowledge.sakura.ad.jp/42901/\n",
            "東京大学の三輪敬太氏は、2024年度の未踏IT人材発掘・育成事業で「ニューラルかな漢字変換システム」の開発に取り組みました。この新しい手法は、従来の統計的な変換手法に比べて高精度な変換を実現しており、実用レベルの性能を持つアプリケーション「Zenzai」として実装されています。今後も、ニューラルかな漢字変換の分野では、さらなる研究と開発が期待されています。\n",
            "\n",
            "#### 〇 失業手当、自己都合退職でも早めにもらえるように　労働者と企業にどんなメリット？：4月1日から - ITmedia ビジネスオンライン\n",
            "https://www.itmedia.co.jp/business/articles/2503/26/news036.html\n",
            "4月1日から、会社を自己都合で退職した場合の失業手当支給開始までの期間が短縮されます。従来は2カ月以上かかっていましたが、改正により1カ月に短縮されます。ただし、過去5年間に3回以上自己都合退職した場合は3カ月の制限期間が設けられます。また、退職後に一定の訓練を受けた場合は給付制限期間がなくなります。\n",
            "\n",
            "\n",
            "### 【技術解説】\n",
            "#### 〇 MCPサーバー自作入門\n",
            "https://zenn.dev/zaki_yama/articles/mcp-server-getting-started\n",
            "MCP (Model Context Protocol) サーバーは、Python、Java、TypeScript などの複数の言語でSDKをサポートしており、ご自身でも開発を試されているとのことです。MCP サーバーの実装方法と、開発したサーバーを Cursor で利用する流れが簡潔に説明されています。また、MCP サーバーの主要な機能や、クライアントの対応状況についても概要が述べられています。\n",
            "\n",
            "\n",
            "### 【新しいLLM】\n",
            "#### 〇 Metaが次世代マルチモーダルAI「Llama 4」をリリース、MoEアーキテクチャ採用で競合モデルに匹敵する高性能を誇る\n",
            "https://gigazine.net/news/20250407-meta-llama-4-released/\n",
            "Meta社が次世代のネイティブマルチモーダルAIモデル「Llama 4」シリーズを発表しました。Llama 4シリーズは画像や動画などを統合的に処理できる革新的な設計で、モデルの精度と効率を大幅に向上させた最新のAIテクノロジーを搭載しています。また、言語サポートの拡大や偏見軽減にも取り組んでおり、今後のMetaのAIアシスタントに順次組み込まれる予定です。\n",
            "\n",
            "#### 〇 Welcome Llama 4 Maverick & Scout on Hugging Face\n",
            "https://huggingface.co/blog/llama4-release\n",
            "Meta社から次世代の大規模言語モデル「Llama 4」がHugging Faceハブに登場しました。Maverick、Scoutの2つのモデルがリリースされ、画像と文章の入力に対応する新しいマルチモーダル機能を備えています。Llama 4は40兆トークンの大規模データを用いて訓練されており、12言語をサポートしています。これらのモデルは、Hugging Faceエコシステムとの完全な統合により、優れた性能を発揮することが期待されています。\n",
            "\n",
            "#### 〇 GitHub - joanrod/star-vector: StarVector is a foundation model for SVG generation that transforms vectorization into a code generation task. Using a vision-language modeling architecture, StarVector processes both visual and textual inputs to produce high-quality SVG code with remarkable precision.\n",
            "https://github.com/joanrod/star-vector\n",
            "StarVectorは、Scalable Vector Graphics (SVG)の生成のための多様なビジョン-言語モデルです。画像からSVGコードを生成する「image2SVG」と、テキストからSVGコードを生成する「text2SVG」の2つの機能を持ちます。このモデルは、言語モデルの力を活用して、SVG生成のスキルを獲得しています。\n",
            "\n",
            "#### 〇 Gemini 2.5: Our most intelligent AI model\n",
            "https://deepmind.google/discover/blog/gemini-2-5-our-most-intelligent-ai-model/\n",
            "最新の「Gemini 2.5」は、先進的な推論能力を持つAIモデルです。従来のモデルよりも著しく高い性能を発揮し、複雑な課題にも対応できるようになりました。「Gemini 2.5 Pro Experimental」は、様々なベンチマークで最先端の成績を収めており、web アプリの開発やプログラミングなど、幅広い分野での活用が期待されています。\n",
            "\n",
            "#### 〇 DeepSeek-V3をアップデートした「DeepSeek-V3-0324」はあらゆるテストで高速化、「最高の非推論モデルになった」との意見も\n",
            "https://gigazine.net/news/20250325-deepseek-v3-0324/\n",
            "中国のAI企業・DeepSeekが、6850億個のパラメーターを持つ大規模言語モデル「DeepSeek-V3-0324」をオープンソースで公開しました。この新モデルはFP8量子化をサポートしており、Mac Studioなどのハードウェアでも高速な推論が可能であることが確認されています。\n",
            "\n",
            "#### 〇 Alibabaが新たなAIモデル「Qwen2.5-VL-32B」をオープンソースでリリース、画像解析や数学の能力が向上\n",
            "https://gigazine.net/news/20250325-qwen2-5-vl-32b-alibaba/\n",
            "Alibaba Cloudの研究チームは、視覚言語モデル「Qwen2.5-VL-32B」を開発しました。このモデルは、同程度のパラメーター数を持つモデルよりも優れた性能を示しており、より大規模なモデルQwen2-VL-72Bにも匹敵する能力を持っています。特に数学の問題解決能力が向上しており、制限速度の把握や正方形の面積計算など、様々な課題に適切に対応することができます。\n",
            "\n",
            "#### 〇 DeepSeek R1のパフォーマンスと価格に匹敵する新しいAIモデル「Hunyuan T1」をTencentが公開\n",
            "https://gigazine.net/news/20250324-tencent-hunyuan-t1/\n",
            "Tencentは2025年3月22日に、大規模言語モデル「Hunyuan-T1」を発表しました。Hunyuan-T1は、DeepSeek R1と同等以上のパフォーマンスを示しつつ、コストも低廉であることが特徴です。ただし、中国政府にとって敏感な話題に関しては、Hunyuan-T1やDeepSeek R1ともに回答を拒否する傾向にあるとの指摘がされています。\n",
            "\n",
            "\n",
            "### 【新サービス】\n",
            "#### 〇 GitHub - openai/codex: Lightweight coding agent that runs in your terminal\n",
            "https://github.com/openai/codex\n",
            "Codex CLIは、ターミナル上で動作するライトウェイトなプログラミングエージェントです。簡単にインストールできる上、プロンプトを入力するだけで、ファイルの生成、サンドボックス内での実行、不足する依存関係のインストールといった一連の処理を自動的に行うことができます。開発者にとって便利なツールとなっています。\n",
            "\n",
            "#### 〇 Notion、AIでメール自動整理「Notionメール」一般公開　まず英語版から - ITmedia AI＋\n",
            "https://www.itmedia.co.jp/aiplus/articles/2504/16/news136.html\n",
            "Notion Labsが新しいメールアプリ「Notionメール」を一般提供開始しました。AIによる自動ラベル付け、重要度に応じた受信トレイ整理、文章提案機能など、Notionのインターフェースを活用したメーラーです。メールデータの安全性にも配慮しており、SOC2認証やGDPRに準拠しているとのことです。\n",
            "\n",
            "#### 〇 Claudeに「Research」機能が追加される、ウェブ上のデータだけでなくGmailやGoogleカレンダーの内容も参照して推論可能\n",
            "https://gigazine.net/news/20250416-claude-research/\n",
            "Anthropicは、チャットAIシステム「Claude」にGoogleサービスとの連携機能を追加しました。これにより、ユーザーはメール履歴やカレンダー、営業情報などを活用して、より詳細な調査や分析を行うことができるようになりました。また、組織内のGoogle文書を検索・活用することで、より包括的な回答を得られるようになっています。これらの機能は、Claudeの有料プランで利用可能です。\n",
            "\n",
            "#### 〇 Generate videos in Gemini and Whisk with Veo 2\n",
            "https://deepmind.google/discover/blog/generate-videos-in-gemini-and-whisk-with-veo-2/\n",
            "Geminiアプリ及びWhiskの新機能「Veo 2」が、本日より一部ユーザーに提供されました。Veo 2を使うことで、テキストプロンプトから高品質な動画を生成することができます。また、生成した動画をモバイルから簡単に共有することも可能です。ただし、生成された動画に不適切な内容が含まれる可能性もあるため、ユーザーからのフィードバックを受け取り、継続的な改善を行っていくとしています。\n",
            "\n",
            "#### 〇 Claude、GmailやカレンダーなどGoogle Workspaceと連携開始\n",
            "https://www.watch.impress.co.jp/docs/news/2007148.html\n",
            "Anthropicは、AI サービス「Claude」に新たな機能を追加しました。Google Workspace との連携により、社内業務の文脈やWebの情報を検索し、意思決定や行動に役立てられるようになりました。また、詳細な情報を検索し、まとめてくれる「リサーチ」機能も、一部地域で初期ベータ版が利用可能となりました。これらの機能強化により、ユーザーの業務効率を高めることが期待されています。\n",
            "\n",
            "#### 〇 GitHub、Issueを分割し親子関係を設定できる「Sub-Issues」が正式機能に\n",
            "https://www.publickey1.jp/blog/25/githubissuesub-issues_1.html\n",
            "GitHubは、これまでパブリックプレビューだった「Sub-Issues」機能を正式版としてリリースしました。Sub-Issuesは大きなIssueを小さなIssueに分割し、親子関係を持たせることができる機能で、Issueに関連したタスクの依存関係や進捗管理が分かりやすくなると期待されています。\n",
            "\n",
            "#### 〇 最強の検索AI「Genspark」触ってみた。未来すぎる。 - Qiita\n",
            "https://qiita.com/jin112343/items/a3e3c8319c45a428748e?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items\n",
            "Genspark は従来の検索エンジンを大きく超えた多機能な AI アシスタントです。自然言語で質問すると、情報を素早く統合して回答してくれるほか、画像や動画の生成も可能です。さらに、得られた情報をそのままブラウザ上で閲覧し、PDFとして保存することもできる便利なツールです。Genspark の能力は日々進化しており、今後の活用が期待されています。ただし、得られた情報を鵜呑みにせず、慎重に確認する必要があります。\n",
            "\n",
            "#### 〇 NTT、デバイス上で実行できる「超高精細映像」のAI推論LSI\n",
            "https://www.watch.impress.co.jp/docs/news/2005626.html\n",
            "NTTは、電力制約のあるエッジやデバイスでも4K映像のリアルタイムAI推論を可能にするAI推論LSIを開発しました。独自の手法により、小さな物体から大きな構造物まで同時に検出でき、ドローンなどのエッジ端末でも150mまでの検出が可能となりました。この技術は4月に米国で開催された研究開発イベントで紹介されています。\n",
            "\n",
            "#### 〇 Agent mode: available to all users and supports MCP\n",
            "https://code.visualstudio.com/blogs/2025/04/07/agentMode\n",
            "VS Code に Agent モードが導入されました。このモードでは、コードベースの分析や、ファイルの編集提案、ターミナルコマンドの実行など、複数のコーディングタスクを自動で行うことができます。また、コンパイルやリントのエラーにも対応し、タスクが完了するまでループして修正を行います。さらに、外部のMCPサーバーやVS Codeの拡張機能とも連携することで、様々なタスクを実行できるようになりました。\n",
            "\n",
            "#### 〇 Streamlitがついに画像・ドキュメント添付に対応！Claude 3.7 Sonnetと連携したマルチモーダルチャットの作り方 - Qiita\n",
            "https://qiita.com/moritalous/items/d0fa45e4d0349f9326a0?utm_campaign=popular_items&utm_medium=feed&utm_source=popular_items\n",
            "Streamlitのチャット入力機能に、添付ファイル（画像、PDF等）に対応する新機能が1.43.0バージョンから追加されました。ユーザーは画像やドキュメントをチャット入力欄にアップロードできるようになり、それらのファイルをConverse APIに送信してアプリケーションに活用することができます。\n",
            "\n",
            "#### 〇 Copilot code review now generally available · GitHub Changelog\n",
            "https://github.blog/changelog/2025-04-04-copilot-code-review-now-generally-available/\n",
            "GitHubの新機能「Copilot code review」が一般公開されました。Copilotを使えば、基本的なコードレビューをAIエージェントに任せることができ、バグの発見や効率化の提案も受けられます。これにより、人間によるレビューを待つ間も開発を進められるようになり、コードの品質向上と維持がより容易になると期待されています。\n",
            "\n",
            "#### 〇 【最新!】Devin 2.0 衝撃大幅アップデート！月500$→従量課金20$から使えるようになったってマジ？未来の開発AIエージェントの実力と未来とは？｜あきらパパ\n",
            "https://note.com/akira_papa_ai/n/ndbeff1db669b\n",
            "Devin 2.0は、従来の月額制から、より使い勝手の良い従量課金制に移行しました。月額$20から利用でき、Devinの活動に応じてACUを消費するシステムになりました。ACUは柔軟な開発をサポートし、待機時間や並列処理などでコストがかからないよう設計されています。このアップデートにより、小規模な開発者でも気軽にDevinの高度な機能を活用できるようになり、開発現場の生産性向上に大きな期待が寄せられています。\n",
            "\n",
            "#### 〇 Docker Model Runner登場、Dockerコンテナと同じように任意の大規模言語モデルをDocker Hubから選んで簡単に導入、実行可能に\n",
            "https://www.publickey1.jp/blog/25/docker_model_runnerdockerdocker_hub.html\n",
            "Docker社は最新のDocker Desktop 4.40にて、大規模言語モデルをDocker Hubから簡単にインストールし、ローカル環境で実行できる「Docker Model Runner」機能を新たに提供しました。この機能はNVIDIA GPUやApple Sillicon向けのGPUアクセラレーションに対応しており、OpenAI APIを介して言語モデルにアクセスできます。これにより、大規模言語モデルの導入が以前に比べて大幅に簡便化され、AIアプリケーション開発の効率化が期待されています。Docker Hubには既にいくつかの有名な大規模言語モデルのパッケージが公開されているほか、Windows版の提供も間もなく行われる見通しです。\n",
            "\n",
            "#### 〇 GoogleがAIアルゴリズムの「DreamerV3」を開発、「人間のデータなしでマインクラフトのダイヤモンドを採掘できる最初のAI」\n",
            "https://gigazine.net/news/20250403-google-deepmind-dreamerv3/\n",
            "グーグルのDeepMindチームが開発した「DreamerV3」は、人気ゲームソフト「マインクラフト」の環境から自ら学習し、ダイヤモンドを採掘することができるAIアルゴリズムです。開発者によると、DreamerV3は未知の環境を学習し、最適な行動を見出すことが可能で、現実世界でのロボット制御などにも応用できると期待されています。\n",
            "\n",
            "#### 〇 「NotebookLM」に新機能「ソースを発見」、指示したとおりに自動でWeb文献を収集・提案／新しい概念を学んだり、重要な参考文献を集めるのが簡単に\n",
            "https://forest.watch.impress.co.jp/docs/news/2003730.html\n",
            "Googleは「NotebookLM」に新機能「ソースを発見」を追加しました。ユーザーが探したいトピックを入力すると、関連性の高いWebソースを数秒で提案し、ワンクリックでノートブックに追加できるようになりました。この機能は本日より段階的に利用可能となる予定です。\n",
            "\n",
            "#### 〇 Claude for Edu開始　答えでなはなく推論プロセスを導く\n",
            "https://www.watch.impress.co.jp/docs/news/2004013.html\n",
            "Anthropicは、教育機関向けのAIサービス「Claude for Education」を発表しました。この新しいサービスは、大学における教育、学習、管理業務全体にAIを活用するための仕組みを提供し、学生の推論プロセスを重視した「学習モード」が特徴となっています。また、教員や事務スタッフ向けの機能も備えており、ノースイースタン大学やLSE、チャムリン・カレッジなどで全学的に導入が進められています。\n",
            "\n",
            "#### 〇 Visual Studio Code 1.98公開　ターミナルの入力補完を強化する「ターミナル IntelliSense」など新機能は？：Copilot Chatでコードベースの検索が可能になるなど、開発体験を強化 - ＠IT\n",
            "https://atmarkit.itmedia.co.jp/ait/articles/2503/25/news094.html\n",
            "VS Codeの最新版「February 2025」では、GitHub Copilotに関する新機能「Next Edit Suggestions」の折りたたみモードやノートブック編集のサポート、Copilot Chatでの画像サポート「Copilot Vision」、コード検索の向上、ターミナルのIntelliSense強化など、開発者の生産性を大幅に向上させる機能が追加されました。また、カスタム指示機能の一般提供も開始され、ユーザーのワークフローに合わせてCopilotの動作をカスタマイズできるようになりました。\n",
            "\n",
            "#### 〇 さくらインターネットが“ビジネスマッチング”提供　認知脳科学＆AI活用、ベストマッチな人物を算出 - ITmedia NEWS\n",
            "https://www.itmedia.co.jp/news/articles/2503/25/news180.html\n",
            "さくらインターネットは、認知脳科学の研究を活用したビジネス向けマッチングサービス「Buddies」の提供を開始しました。Buddiesは、ユーザーの行動リズムを測定して数値化し、AIが分析することで自分と相性のいい人物を導き出す新しいサービスです。\n",
            "Buddiesでは、ユーザーがやりたいことや自身のスキルを入力すると、テキスト解析AIによって他者との関係を分析し、相性のいい人物を提案してくれるため、イノベーションを起こすためのパートナーやプロジェクトアイデアの発見に役立つと期待されています。\n",
            "\n",
            "#### 〇 Takumi - 日本初・セキュリティ診断AIエージェント | GMO Flatt Security\n",
            "https://flatt.tech/takumi\n",
            "GMOのセキュリティAIツール「Takumi」は、Slackでいつでも脆弱性診断を依頼できる便利なサービスです。高度なセキュリティ診断やコードの情報収集を自律的に行い、GitHubやShisho Cloudの変化にも積極的に対応することができます。また、Dependabotのトリアージや既知の脆弱性の影響調査など、さまざまな用途で活用できるユーザーの味方となってくれるツールです。\n",
            "\n",
            "#### 〇 Second Me\n",
            "https://www.secondme.io/\n",
            "Second Meは、個人の価値観や経験、嗜好を反映した独自のAIアシスタントを提供し、ユーザーの本質的な自我を維持しつつ、状況に応じて柔軟に対応できる仕組みを提案しています。また、Second Meは個人のデータを分散管理するシステムを採用し、ユーザーが自身の情報を完全に管理できるようにしています。これは、現在のAIパラダイムを打破し、より分散型かつ個人主導のAI活用を実現するものとなっています。\n",
            "\n",
            "#### 〇 グーグル「NotebookLM」にみんな大好き「マインドマップ」機能が追加！\n",
            "https://ascii.jp/elem/000/004/258/4258466/\n",
            "グーグルは、AIノートアプリ「NotebookLM」にインタラクティブなマインドマップ機能を導入しました。この新機能により、ユーザーはアップロードしたソースを視覚的に要約し、主要なトピックと関連するアイデアを分岐図として表示できるようになりました。簡単な手順で使用できるこの機能は、長い文章を読むよりも全体的な構造と主要テーマを把握しやすくなっています。\n",
            "\n",
            "#### 〇 Claude can now search the web\n",
            "https://www.anthropic.com/news/web-search\n",
            "クロードを使えば、最新の情報を活用した適切な回答が得られるようになりました。クロードは、ウェブ検索を通して最新のデータにアクセスでき、より正確な情報提供が可能になっています。また、ウェブ検索の結果に直接出典を示すため、情報の信頼性も確認できます。\n",
            "\n",
            "\n",
            "### 【新技術】\n",
            "#### 〇 パナソニック、学習してない物体をテキストと画像で指示できる対話型セグメンテーションAI技術「SegLLM」を開発 - ロボスタ ロボスタ - ロボット情報WEBマガジン\n",
            "https://robotstart.info/2025/04/17/pana-segllm.html\n",
            "パナソニックHDとPRDCAが、UC Berkeleyの研究者らと共同で開発した「SegLLM」は、テキストと参照画像を用いて認識対象を指示できる対話型セグメンテーション技術です。この技術は、過去の対話で認識した対象を基に新しい指示を出す際の課題を解決し、高精度な対話型セグメンテーションを実現しました。今後、この技術は自動アノテーションツールへの実装や、多様な器具・工具が存在する現場での活用が期待されています。\n",
            "\n",
            "#### 〇 神経科学：麻痺患者のためのリアルタイムで思考を音声に変換する装置の開発 | Nature Neuroscience | Nature Portfolio\n",
            "https://www.natureasia.com/ja-jp/research/highlight/15197\n",
            "脳内の音声活動を即座に音声に変換する新しい装置が開発された。この装置は会話の自然な流れを回復させ、話すことができない患者の生活の質を向上させる可能性がある。さらなる研究が必要だが、この装置は言語障害のある患者のためのより良いコミュニケーションツールになると期待されている。\n",
            "\n",
            "\n",
            "### 【画像生成AI】\n",
            "#### 〇 AI tool generates high-quality images faster than state-of-the-art approaches\n",
            "https://news.mit.edu/2025/ai-tool-generates-high-quality-images-faster-0321\n",
            "研究者らは、オートリグレッシブモデルと拡散モデルの長所を組み合わせた新しいアプローチを開発しました。この手法は「HART」と呼ばれ、拡散モデルに匹敵する高品質な画像を生成できますが、約9倍の速さを実現しています。HARTは、ロボットの訓練やビデオゲームの描画など、さまざまな応用が期待されています。\n",
            "\n",
            "\n",
            "### 【音声AI】\n",
            "#### 〇 OpenAIにおける文字起こし（音声認識）の現在地 | DevelopersIO\n",
            "https://dev.classmethod.jp/articles/openai-transcribe/\n",
            "OpenAIでは文字起こし（音声認識）を実現するための最新の方法が整理されており、ネイティブにマルチモーダルに対応したモデルが3つ用意されています。Realtime APIを使うことで、音声認識と音声合成を組み合わせることにより、AIとの音声による自然な対話が可能となり、低遅延でマルチモーダルな体験をアプリに組み込めるようになります。Python を使って、WebSocket接続を用いてリアルタイムの音声認識を行う方法について解説しています。\n",
            "\n",
            "#### 〇 流暢にしゃべる「重音テト」登場　AHSから文字読み上げソフト「VOICEPEAK」発売へ - ITmedia NEWS\n",
            "https://www.itmedia.co.jp/news/articles/2504/01/news131.html\n",
            "AHS社が4月24日に、AI音声合成技術を用いた文字読み上げソフト「VOICEPEAK 重音テト」を発売すると発表しました。このソフトは、任意のテキストを入力して高品質な音声を作成でき、複数の感情表現にも対応しています。また、他のVOICEPEAK製品とも連携し、セリフごとに登場人物の声を切り替えられる「掛け合い」機能も備えています。\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}